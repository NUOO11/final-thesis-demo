import streamlit as st
import spacy
import nltk
from nltk.corpus import wordnet
from graphviz import Digraph
import os

# ==========================================
# 0. ç¯å¢ƒé…ç½® (é˜²æ­¢æœ¬åœ° Graphviz æŠ¥é”™)
# ==========================================
# os.environ["PATH"] += os.pathsep + r'C:\Program Files\Graphviz\bin'

# ==========================================
# 1. èµ„æºåŠ è½½ä¸é…ç½®
# ==========================================
st.set_page_config(page_title="NLP to UML (Thesis Edition)", page_icon="ğŸ“", layout="wide")

st.markdown("""
<style>
    .main .block-container { padding-top: 2rem; }
    div[data-testid="stGraphvizChart"] {
        text-align: center;
        border: 1px solid #e6e6e6;
        border-radius: 8px;
        padding: 10px;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# Session State
if 'generated_classes' not in st.session_state: st.session_state['generated_classes'] = {}
if 'graph_dot' not in st.session_state: st.session_state['graph_dot'] = None

@st.cache_resource
def load_nlp_resources():
    # 1. ä¸‹è½½ WordNet (ç”¨äº Ontology Check)
    try:
        nltk.data.find('corpora/wordnet.zip')
    except LookupError:
        nltk.download('wordnet')
        nltk.download('omw-1.4')
    
    # 2. åŠ è½½ Spacy æ¨¡å‹ (é’ˆå¯¹ Streamlit Cloud çš„ç»ˆæé˜²å¾¡å†™æ³•)
    try:
        # å°è¯•ç›´æ¥ import (å¦‚æœ requirements.txt URL ç”Ÿæ•ˆ)
        import en_core_web_sm
        return en_core_web_sm.load()
    except ImportError:
        # å¦‚æœ import å¤±è´¥ï¼Œå°è¯•æ ‡å‡†åŠ è½½
        try:
            return spacy.load("en_core_web_sm")
        except:
            return None

nlp = load_nlp_resources()

# ==========================================
# 2. æ ¸å¿ƒç®—æ³•é€»è¾‘ (Phase 3: Extraction Rules)
# ==========================================
class ThesisUMLSystem:
    def __init__(self, nlp_model):
        self.nlp = nlp_model
        self.classes = {}
        self.relationships = []
        # è¿‡æ»¤æ‰éå®è´¨æ€§åŠ¨è¯
        self.ignored_verbs = {"be", "have", "include", "consist", "contain", "involve"}

    def check_ontology(self, word):
        """
        åˆ©ç”¨ WordNet éªŒè¯æå–çš„è¯æ˜¯å¦å…·å¤‡åè¯å®ä½“çš„è¯­ä¹‰ï¼Œ
        é¿å…æå–å‡º "system", "process" ç­‰æŠ½è±¡æ³›è¯ï¼ˆè®ºæ–‡åˆ›æ–°ç‚¹ä¹‹ä¸€ï¼‰ã€‚
        """
        try:
            synsets = wordnet.synsets(word)
            if not synsets: return True
            # åªä¿ç•™ä¸»è¦çš„ Noun ä¹‰é¡¹
            return any(s.pos() == 'n' for s in synsets)
        except: return True

    def detect_multiplicity(self, token):
        """
        åŸºäºè¯­ä¹‰åˆ†ææ¨æ–­ UML çš„é‡æ•° (Multiplicity)
        """
        for child in token.children:
            if child.text.lower() in ["many", "multiple", "list", "set", "all", "collection"]: 
                return "1..*"
            if child.tag_ == "NNS": # å¤æ•°åè¯
                return "0..*"
        return "1"

    def process(self, text):
        if not self.nlp: return None
        
        self.classes = {}
        self.relationships = []
        doc = self.nlp(text)
        
        for token in doc:
            # --- Rule 1: Class Identification (åŸºäº Ontology) ---
            if token.pos_ in ["NOUN", "PROPN"] and token.dep_ in ["nsubj", "dobj", "pobj", "nsubjpass"]:
                lemma = token.lemma_.lower()
                # è¿‡æ»¤é»‘åå• (æ ¹æ®è®ºæ–‡è®¾å®š)
                if lemma not in ["user", "data"]: 
                    if self.check_ontology(lemma):
                        c = token.lemma_.capitalize()
                        if c not in self.classes: 
                            self.classes[c] = {'attributes': set(), 'methods': set()}

            # --- Rule 2: Generalization (ç»§æ‰¿å…³ç³») ---
            if token.lemma_ == "be":
                subj = [c for c in token.children if c.dep_ == "nsubj"]
                attr = [c for c in token.children if c.dep_ == "attr"]
                if subj and attr:
                    c = subj[0].lemma_.capitalize()
                    p = attr[0].lemma_.capitalize()
                    if c in self.classes and p in self.classes: 
                        self.relationships.append((c, "Generalization", p, ""))
            
            # --- Rule 3: Composition/Aggregation (æ•´ä½“-éƒ¨åˆ†) ---
            elif token.lemma_ in ["have", "contain", "include", "consist"]:
                owners = [c for c in token.children if c.dep_ == "nsubj"]
                objs = [c for c in token.children if c.dep_ == "dobj"]
                if owners and objs:
                    o = owners[0].lemma_.capitalize()
                    mult = self.detect_multiplicity(objs[0])
                    mlabel = mult if mult != "1" else ""
                    if o in self.classes:
                        obj_c = objs[0].lemma_.capitalize()
                        if obj_c in self.classes: 
                            # è¯†åˆ«ä¸ºç±»ä¹‹é—´çš„å…³ç³»
                            self.relationships.append((o, "Composition", obj_c, mlabel))
                        else: 
                            # é™çº§ä¸ºå±æ€§
                            self.classes[o]['attributes'].add(objs[0].text)

            # --- Rule 4: Association (å¸¸è§„å…³è”) ---
            elif token.pos_ == "VERB" and token.lemma_ not in self.ignored_verbs:
                subjs = [c for c in token.children if c.dep_ == "nsubj"]
                if subjs:
                    s = subjs[0].lemma_.capitalize()
                    if s in self.classes:
                        self.classes[s]['methods'].add(token.lemma_)
                        dobjs = [c for c in token.children if c.dep_ == "dobj"]
                        if dobjs:
                            o = dobjs[0].lemma_.capitalize()
                            if o in self.classes and s != o: 
                                self.relationships.append((s, "Association", o, token.lemma_))

            # --- Rule 5: Passive Voice Handling (è¢«åŠ¨è¯­æ€) ---
            # e.g., "Account is managed by Admin"
            if token.dep_ == "agent" and token.head.pos_ == "VERB":
                actual_agent = [c for c in token.children if c.dep_ == "pobj"] # Admin
                verb = token.head # managed
                passive_subj = [c for c in verb.children if c.dep_ == "nsubjpass"] # Account
                
                if actual_agent and passive_subj:
                    act = actual_agent[0].lemma_.capitalize()
                    rec = passive_subj[0].lemma_.capitalize()
                    
                    # ç¡®ä¿ç±»å­˜åœ¨
                    if act not in self.classes: self.classes[act] = {'attributes': set(), 'methods': set()}
                    if rec not in self.classes: self.classes[rec] = {'attributes': set(), 'methods': set()}
                    
                    self.classes[act]['methods'].add(verb.lemma_)
                    self.relationships.append((act, "Association", rec, verb.lemma_))

        return self.generate_graphviz()

    def generate_graphviz(self):
        """
        Phase 4: Rendering Engine (using Graphviz)
        å®Œå…¨ç¬¦åˆè®ºæ–‡ä¸­æè¿°çš„ 'Visual Mapping' è¿‡ç¨‹
        """
        dot = Digraph(comment='Thesis UML')
        dot.attr(rankdir='BT', splines='ortho', nodesep='0.8', ranksep='0.8')
        dot.attr('node', shape='record', style='filled', fillcolor='#FEFECE', fontname='Helvetica', fontsize='12')
        
        # 1. Nodes (Classes)
        for class_name, details in self.classes.items():
            attrs = r"\l".join([f"- {a}" for a in details['attributes']]) + r"\l" if details['attributes'] else ""
            methods = r"\l".join([f"+ {m}()" for m in details['methods']]) + r"\l" if details['methods'] else ""
            
            # ä½¿ç”¨ Record Shape æ¨¡æ‹Ÿ UML ç±»å›¾æ¡†
            label = f"{{ {class_name} | {attrs} | {methods} }}"
            dot.node(class_name, label=label)

        # 2. Edges (Relationships)
        unique_rels = set(self.relationships)
        for s, r_type, t, label in unique_rels:
            if r_type == "Generalization":
                dot.edge(s, t, arrowhead='onormal', label='') # ç»§æ‰¿ç©ºå¿ƒä¸‰è§’
            elif r_type == "Composition":
                dot.edge(s, t, dir='both', arrowtail='diamond', arrowhead='none', label=label) # ç»„åˆå®å¿ƒè±å½¢
            else:
                dot.edge(s, t, arrowhead='vee', label=label) # å…³è”æ™®é€šç®­å¤´

        return dot

# ==========================================
# 3. ç•Œé¢äº¤äº’ (Thesis Presentation UI)
# ==========================================
st.title("ğŸ“ Automatic UML Generation System")
st.caption("Master's Thesis Project | NLP to UML Transformation Pipeline")

if nlp is None:
    st.error("âš ï¸ Model Loading Error")
    st.info("System could not load 'en_core_web_sm'. Please check requirements.txt.")
else:
    system = ThesisUMLSystem(nlp)
    
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("1. Input Requirements")
        txt = st.text_area("Natural Language Spec:", 
                          "The BankSystem contains many Accounts.\nAn Account is owned by a Customer.\nThe Administrator manages the System.", 
                          height=200)
        
        if st.button("Generate Diagram", type="primary"):
            with st.spinner("Analyzing semantics..."):
                try:
                    graph = system.process(txt)
                    st.session_state['graph_dot'] = graph
                    st.session_state['generated_classes'] = system.classes
                except Exception as e:
                    st.error(f"Analysis Failed: {e}")

        # Evaluation Section
        st.markdown("---")
        st.subheader("3. Validation (F1-Score)")
        gt = st.text_input("Ground Truth Classes (comma-separated):", "BankSystem, Account, Customer, Administrator")
        
        if st.button("Calculate Metrics"):
            if st.session_state['generated_classes']:
                # F1 Calculation Logic
                exp = set([x.strip().lower() for x in gt.split(",") if x.strip()])
                det = set([x.lower() for x in st.session_state['generated_classes'].keys()])
                
                tp = len(exp.intersection(det))
                fp = len(det - exp)
                fn = len(exp - det)
                
                p = tp/(tp+fp) if (tp+fp)>0 else 0
                r = tp/(tp+fn) if (tp+fn)>0 else 0
                f1 = 2*(p*r)/(p+r) if (p+r)>0 else 0
                
                st.metric("F1-Score", f"{f1:.2f}")
                st.text(f"Precision: {p:.2f} | Recall: {r:.2f}")
            else:
                st.warning("Generate a diagram first.")

    with col2:
        st.subheader("2. Generated Model")
        if st.session_state['graph_dot']:
            st.graphviz_chart(st.session_state['graph_dot'])
            with st.expander("Show DOT Source (for verification)"):
                st.code(st.session_state['graph_dot'].source)
        else:
            st.info("Waiting for input...")